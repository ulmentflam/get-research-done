---
phase: 05-human-evaluation-gate
plan: 02
type: execute
wave: 2
depends_on: ["05-01"]
files_modified:
  - commands/grd/evaluate.md
  - get-research-done/templates/iteration-summary.md
autonomous: true

must_haves:
  truths:
    - "User sees executive summary first (hypothesis, verdict, key metric)"
    - "User can request drill-down into data, iterations, or critic reasoning"
    - "User receives Seal/Iterate/Archive decision prompt after evidence review"
    - "Archive decision requires confirmation and rationale"
    - "Iterate decision shows Critic's recommended direction"
  artifacts:
    - path: "commands/grd/evaluate.md"
      provides: "Complete evidence presentation and decision gate implementation"
      contains: "Executive Summary"
    - path: "get-research-done/templates/iteration-summary.md"
      provides: "Template for collapsed iteration history in archives"
      min_lines: 25
  key_links:
    - from: "commands/grd/evaluate.md"
      to: "experiments/run_NNN/CRITIC_LOG.md"
      via: "extracts recommendations for Iterate routing"
      pattern: "CRITIC_LOG.md.*Recommendations"
---

<objective>
Implement evidence package presentation and interactive decision gate with Seal/Iterate/Archive flow.

Purpose: Complete the human-in-the-loop experience by presenting evidence in executive summary format (leading with outcome) and capturing user decisions with appropriate confirmation flows. This satisfies HUMAN-01 (evidence package) and HUMAN-02 (decision gate).

Output: Fully interactive /grd:evaluate command that presents evidence adaptively and captures human decisions.
</objective>

<execution_context>
@/Users/evanowen/.claude/get-research-done/workflows/execute-plan.md
@/Users/evanowen/.claude/get-research-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-human-evaluation-gate/05-CONTEXT.md
@.planning/phases/05-human-evaluation-gate/05-RESEARCH.md
@.planning/phases/05-human-evaluation-gate/05-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement evidence presentation in evaluate command</name>
  <files>commands/grd/evaluate.md</files>
  <action>
Replace Phase 2 placeholder in /grd:evaluate with complete evidence presentation logic.

**Executive summary first (from 05-CONTEXT.md):**

Display banner and executive summary immediately:

```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 GRD ► EVIDENCE PACKAGE: {run_name}
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

## Executive Summary

**Hypothesis:** {brief_hypothesis_from_OBJECTIVE}
**Verdict:** {VALIDATED|FAILED|INCONCLUSIVE} ({confidence} confidence)
**Key Result:** {primary_metric}={value} (target: {comparison}{threshold}) {PASS|FAIL}
**Composite Score:** {score} (threshold: {threshold})

**Recommendation:** {one_sentence_recommendation}
```

**Verdict determination logic:**
- VALIDATED: Critic PROCEED + composite_score >= threshold + overall_result = PASS
- FAILED: composite_score < threshold OR overall_result = FAIL
- INCONCLUSIVE: Critic PROCEED with LOW confidence OR mixed metric results

**Drill-down sections (Claude decides based on complexity):**

After executive summary, Claude adaptively presents relevant sections:

1. **Data Characteristics** (if DATA_REPORT.md exists and relevant)
   - Sample size, feature count
   - Class balance if applicable
   - Any leakage warnings that were addressed

2. **Iteration Timeline** (if multiple iterations)
   - Brief: "Run 3 of 5 iterations"
   - Expand on request to show full history

3. **Critic Reasoning** (if verdict borderline or concerns exist)
   - Key strengths and weaknesses
   - Why PROCEED was given
   - Any residual concerns

4. **Full Metrics** (if user wants detail)
   - Complete metrics table from SCORECARD.json
   - Per-metric PASS/FAIL with values vs thresholds

**Implementation:**
- Read SCORECARD.json and parse metrics, composite_score, overall_result
- Read CRITIC_LOG.md for verdict, confidence, strengths, weaknesses, recommendations
- Read OBJECTIVE.md for hypothesis statement
- Read DATA_REPORT.md if exists for data context
- Determine verdict category (VALIDATED/FAILED/INCONCLUSIVE)
- Present executive summary
- Gauge user engagement and offer drill-down

Do NOT dump all files as raw text. Present digestible summary with expansion options.
  </action>
  <verify>
```bash
grep -q "Executive Summary" commands/grd/evaluate.md && grep -q "VALIDATED|FAILED|INCONCLUSIVE" commands/grd/evaluate.md && grep -q "Drill-down" commands/grd/evaluate.md && echo "Evidence presentation implemented"
```
  </verify>
  <done>
Evidence presentation implemented with executive summary first, verdict determination logic (VALIDATED/FAILED/INCONCLUSIVE), and adaptive drill-down sections for data, iterations, critic reasoning, and full metrics.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement decision gate with confirmation flows</name>
  <files>commands/grd/evaluate.md</files>
  <action>
Replace Phase 3 placeholder with complete decision gate implementation.

**Decision options (from 05-CONTEXT.md):**

After evidence presentation, prompt user:

```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 GRD ► DECISION GATE
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

How would you like to proceed?

1. **Seal** — Hypothesis validated, ready for production/publication
2. **Iterate** — Continue experimentation (Critic suggests: {direction})
3. **Archive** — Abandon hypothesis, preserve as negative result
```

**Use AskUserQuestion tool:**

```javascript
AskUserQuestion({
  header: "Experiment Decision: {run_name}",
  question: "How would you like to proceed?",
  options: [
    "Seal — Hypothesis validated, ready for production/publication",
    "Iterate — Continue experimentation (Critic suggests: {REVISE_METHOD|REVISE_DATA})",
    "Archive — Abandon hypothesis, preserve as negative result"
  ]
})
```

**Decision handling:**

**If Seal:**
- No confirmation needed (affirmative action)
- Proceed directly to decision logging
- Display: "Hypothesis sealed. Decision logged."

**If Iterate:**
- Extract Critic's last recommendation from CRITIC_LOG.md
- Auto-suggest direction:
  - If REVISE_METHOD: "Continue with method refinement. Run /grd:research --continue"
  - If REVISE_DATA: "Data concerns identified. Run /grd:explore with specific concerns, then /grd:research --continue"
- Display recommendation and next command
- No confirmation needed

**If Archive:**
- Confirmation gate (destructive action per 05-CONTEXT.md):

```javascript
AskUserQuestion({
  header: "Confirm Archive",
  question: "This will archive all runs and mark the hypothesis as failed. Continue?",
  options: ["Yes, archive with rationale", "Cancel"]
})
```

- If user cancels, return to decision gate
- If user confirms, capture rationale (REQUIRED):

```javascript
AskUserQuestion({
  header: "Archive Rationale",
  question: "Why is this hypothesis being abandoned? (Required - saved in ARCHIVE_REASON.md)",
  // Free-form text input expected from user response
})
```

- Validate rationale is not empty
- If empty, prompt again: "Rationale is required to preserve context for future researchers."
- Proceed to archive handling with captured rationale
  </action>
  <verify>
```bash
grep -q "AskUserQuestion" commands/grd/evaluate.md && grep -q "Seal.*Iterate.*Archive" commands/grd/evaluate.md && grep -q "Confirm Archive" commands/grd/evaluate.md && echo "Decision gate implemented"
```
  </verify>
  <done>
Decision gate implemented with Seal (no confirmation), Iterate (auto-suggest direction from Critic), and Archive (confirmation + required rationale). AskUserQuestion used for all prompts.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create ITERATION_SUMMARY.md template</name>
  <files>get-research-done/templates/iteration-summary.md</files>
  <action>
Create template for collapsed iteration history used when archiving multiple runs.

**Template structure:**

```markdown
# Iteration Summary Template

Template for `experiments/archive/YYYY-MM-DD_hypothesis_name/ITERATION_SUMMARY.md`.

Collapses all iteration attempts into a single summary document when archiving.

---

## File Template

# Iteration Summary: {{hypothesis_name}}

**Total Iterations:** {{N}}
**Date Range:** {{first_run_date}} to {{last_run_date}}
**Outcome:** Archived (hypothesis abandoned)

## Iteration History

| # | Run | Date | Verdict | Confidence | Key Metric | Notes |
|---|-----|------|---------|------------|------------|-------|
| 1 | run_001_baseline | YYYY-MM-DD | REVISE_METHOD | MEDIUM | F1=0.72 | Initial attempt |
| 2 | run_002_tuned | YYYY-MM-DD | REVISE_METHOD | MEDIUM | F1=0.76 | Hyperparameter tuning |
| 3 | run_003_final | YYYY-MM-DD | ESCALATE | LOW | F1=0.78 | Limit reached |

## Metric Trend

**Best achieved:** {{metric}}={{best_value}}
**Target:** {{threshold}}
**Gap:** {{best_value - threshold}}
**Trend:** {{improving|stagnant|degrading}}

## Verdict Distribution

- PROCEED: {{count}}
- REVISE_METHOD: {{count}}
- REVISE_DATA: {{count}}
- ESCALATE: {{count}}

## Key Observations

{{Summary of what was tried and why it didn't work}}

## Preserved Artifacts

- Final run: {{run_NNN_description}}/
- All CRITIC_LOG.md files (merged or individual)
- Final SCORECARD.json

---

*Summary generated on archive. See ARCHIVE_REASON.md for human rationale.*

---

## Usage Notes

- Generated automatically when Archive decision is made
- Collapses N runs into single summary
- Preserves metric trend for future reference
- Key observations should capture what approaches were tried
- References final run directory which is fully preserved
```

This template supports the 05-CONTEXT.md decision to "collapse others into summary" while keeping final run fully preserved.
  </action>
  <verify>
```bash
test -f get-research-done/templates/iteration-summary.md && grep -q "Iteration History" get-research-done/templates/iteration-summary.md && grep -q "Metric Trend" get-research-done/templates/iteration-summary.md && echo "Template created"
```
  </verify>
  <done>
ITERATION_SUMMARY.md template exists with iteration history table, metric trend analysis, verdict distribution, key observations section, and preserved artifacts reference.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

```bash
# Verify evidence presentation
grep -c "Executive Summary" commands/grd/evaluate.md | grep -q "[1-9]" && echo "Executive summary present"
grep -q "VALIDATED" commands/grd/evaluate.md && grep -q "FAILED" commands/grd/evaluate.md && echo "Verdict logic present"

# Verify decision gate
grep -q "AskUserQuestion" commands/grd/evaluate.md && echo "Interactive prompts present"
grep -q "Archive.*rationale" commands/grd/evaluate.md && echo "Archive rationale flow present"
grep -q "Iterate.*Critic" commands/grd/evaluate.md && echo "Iterate routing present"

# Verify iteration summary template
test -f get-research-done/templates/iteration-summary.md && echo "Iteration summary template exists"
grep -q "Verdict Distribution" get-research-done/templates/iteration-summary.md && echo "Template has verdict tracking"
```

Expected: All evidence presentation, decision gate, and template elements present.
</verification>

<success_criteria>
- [ ] Executive summary displayed first with hypothesis, verdict, key metric
- [ ] Verdict determined as VALIDATED/FAILED/INCONCLUSIVE
- [ ] Drill-down sections available for data, iterations, critic, metrics
- [ ] Decision gate uses AskUserQuestion with three options
- [ ] Archive requires confirmation and mandatory rationale
- [ ] Iterate shows Critic's recommended direction
- [ ] ITERATION_SUMMARY.md template created for archive collapse
</success_criteria>

<output>
After completion, create `.planning/phases/05-human-evaluation-gate/05-02-SUMMARY.md`
</output>
