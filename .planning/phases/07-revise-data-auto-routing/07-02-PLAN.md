---
phase: 07-revise-data-auto-routing
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - agents/grd-explorer.md
  - get-research-done/templates/state.md
autonomous: true

must_haves:
  truths:
    - "Explorer agent handles targeted re-analysis mode (not just initial EDA)"
    - "Explorer appends revision sections to DATA_REPORT.md (preserves original)"
    - "Explorer returns structured recommendation (proceed/critical_issue)"
    - "STATE.md template has Data Revisions table structure"
  artifacts:
    - path: "agents/grd-explorer.md"
      provides: "Revision mode handling in execution flow"
      contains: "Revision: Iteration"
    - path: "get-research-done/templates/state.md"
      provides: "Data Revisions table template"
      contains: "### Data Revisions"
  key_links:
    - from: "agents/grd-explorer.md"
      to: ".planning/DATA_REPORT.md"
      via: "Append revision section"
      pattern: "## Revision: Iteration"
---

<objective>
Extend Explorer agent for targeted re-analysis and enhance STATE.md template for data revision tracking

Purpose: The Explorer agent currently supports initial EDA but needs explicit support for targeted re-analysis mode when spawned by Researcher on REVISE_DATA. This plan adds revision handling and ensures STATE.md template supports data revision tracking.

Output: Modified grd-explorer.md with revision mode support and updated state.md template with Data Revisions table structure.
</objective>

<execution_context>
@/Users/evanowen/.claude/get-shit-done/workflows/execute-plan.md
@/Users/evanowen/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-revise-data-auto-routing/07-RESEARCH.md
@agents/grd-explorer.md
@get-research-done/templates/state.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add revision mode detection to Explorer execution flow</name>
  <files>agents/grd-explorer.md</files>
  <action>
In grd-explorer.md, locate the beginning of `<execution_flow>` section.

Add a new "Step 0: Detect Analysis Mode" before the existing Step 1:

```markdown
## Step 0: Detect Analysis Mode

**Responsibilities:**
- Determine if this is initial EDA or targeted re-analysis (revision mode)
- Parse concerns from spawn prompt if revision mode
- Set analysis scope based on mode

### Mode Detection

**Check for revision indicators in task prompt:**

```python
def detect_analysis_mode(task_prompt: str) -> dict:
    """Determine if Explorer is in initial or revision mode."""
    mode = {
        'type': 'initial',  # or 'revision'
        'concerns': [],
        'iteration': None
    }

    # Check for revision indicators
    revision_indicators = [
        'targeted re-analysis',
        'Revision:',
        'Critic identified',
        'data quality issues during experiment',
        're-analyze the dataset'
    ]

    if any(indicator.lower() in task_prompt.lower() for indicator in revision_indicators):
        mode['type'] = 'revision'

        # Extract concerns from <concerns> section
        import re
        concerns_match = re.search(r'<concerns>(.*?)</concerns>', task_prompt, re.DOTALL)
        if concerns_match:
            concerns_text = concerns_match.group(1)
            # Parse bulleted list
            mode['concerns'] = [
                line.strip().lstrip('- ')
                for line in concerns_text.strip().split('\n')
                if line.strip().startswith('-')
            ]

        # Extract iteration number
        iter_match = re.search(r'Iteration:\s*(\d+)', task_prompt)
        if iter_match:
            mode['iteration'] = int(iter_match.group(1))

    return mode

analysis_mode = detect_analysis_mode(task_prompt)
```

**Mode-specific behavior:**

| Mode | Scope | Output Location | Full Profiling |
|------|-------|-----------------|----------------|
| initial | Full dataset | .planning/DATA_REPORT.md (new file) | Yes |
| revision | Flagged concerns only | .planning/DATA_REPORT.md (append) | No |

**If revision mode:**
- Skip Steps 2-6 unless relevant to concerns
- Focus only on investigation scope
- Append to existing DATA_REPORT.md
- Return structured recommendation
```

Update the start of Step 1 to check analysis_mode and skip to Step 7 variant if revision:

```python
# At start of Step 1
if analysis_mode['type'] == 'revision':
    # Skip to focused re-analysis (Step 7 variant)
    goto_revision_analysis(analysis_mode['concerns'], analysis_mode['iteration'])
```
  </action>
  <verify>grep -A 10 "Step 0: Detect Analysis Mode" agents/grd-explorer.md</verify>
  <done>grd-explorer.md has Step 0 that detects initial vs revision mode and extracts concerns from spawn prompt</done>
</task>

<task type="auto">
  <name>Task 2: Add focused revision analysis workflow to Explorer</name>
  <files>agents/grd-explorer.md</files>
  <action>
In grd-explorer.md, add a new section before Step 10 (Return Completion) titled "Step 7.5: Focused Revision Analysis (Revision Mode Only)":

```markdown
## Step 7.5: Focused Revision Analysis (Revision Mode Only)

**When:** Called in revision mode instead of full Steps 2-7

**Responsibilities:**
- Investigate only the specific concerns from Critic
- Append findings to DATA_REPORT.md (preserve original)
- Return structured recommendation for Researcher

### 7.5.1 Load Existing DATA_REPORT.md

```python
# Read existing report to understand baseline
existing_report_path = '.planning/DATA_REPORT.md'
with open(existing_report_path, 'r') as f:
    existing_report = f.read()

# Extract original findings for comparison
original_findings = parse_original_findings(existing_report)
```

### 7.5.2 Investigate Each Concern

**For each concern from Critic:**

```python
revision_findings = []

for concern in analysis_mode['concerns']:
    finding = {
        'concern': concern,
        'investigation': None,
        'result': None,
        'confidence': 'MEDIUM'
    }

    # Determine investigation type based on concern keywords
    if 'leakage' in concern.lower():
        # Re-run leakage detection on specific features
        feature_names = extract_feature_names(concern)
        finding['investigation'] = 'Leakage re-check'
        finding['result'] = investigate_leakage(df, feature_names, target_col)

    elif 'distribution' in concern.lower() or 'drift' in concern.lower():
        # Check distribution changes
        column_names = extract_column_names(concern)
        finding['investigation'] = 'Distribution analysis'
        finding['result'] = analyze_distribution_drift(df, column_names)

    elif 'train-test' in concern.lower() or 'overlap' in concern.lower():
        # Verify split integrity
        finding['investigation'] = 'Split integrity check'
        finding['result'] = verify_split_integrity(df, split_files)

    elif 'missing' in concern.lower():
        # Re-analyze missing patterns
        finding['investigation'] = 'Missing data re-analysis'
        finding['result'] = analyze_missing_patterns(df)

    elif 'outlier' in concern.lower() or 'anomaly' in concern.lower():
        # Re-run outlier detection
        finding['investigation'] = 'Outlier re-detection'
        finding['result'] = detect_outliers_focused(df)

    else:
        # Generic investigation
        finding['investigation'] = 'General investigation'
        finding['result'] = f"Investigated concern: {concern}. See details below."

    # Assess confidence based on evidence strength
    if finding['result'] and 'confirmed' in str(finding['result']).lower():
        finding['confidence'] = 'HIGH'
    elif finding['result'] and 'not found' in str(finding['result']).lower():
        finding['confidence'] = 'HIGH'
    else:
        finding['confidence'] = 'MEDIUM'

    revision_findings.append(finding)
```

### 7.5.3 Determine Recommendation

```python
def determine_recommendation(findings: list) -> str:
    """Determine proceed/critical_issue based on findings."""
    critical_indicators = [
        'confirmed leakage',
        'significant overlap',
        'critical data issue',
        'fundamental problem',
        'unusable data'
    ]

    for finding in findings:
        result_text = str(finding.get('result', '')).lower()
        if any(indicator in result_text for indicator in critical_indicators):
            return 'critical_issue'

    return 'proceed'

recommendation = determine_recommendation(revision_findings)
overall_confidence = 'HIGH' if all(f['confidence'] == 'HIGH' for f in revision_findings) else 'MEDIUM'
```

### 7.5.4 Append Revision to DATA_REPORT.md

**Generate revision section (append-only):**

```python
revision_section = f"""

---

## Revision: Iteration {analysis_mode['iteration']}

**Triggered by:** Critic REVISE_DATA verdict
**Timestamp:** {datetime.utcnow().isoformat()}Z
**Concerns investigated:** {len(analysis_mode['concerns'])}

### Concerns Addressed

"""

for finding in revision_findings:
    revision_section += f"""
#### {finding['concern']}

**Investigation:** {finding['investigation']}
**Confidence:** {finding['confidence']}

**Findings:**
{finding['result']}

"""

revision_section += f"""
### Revision Summary

**Recommendation:** {recommendation.upper()}
**Overall Confidence:** {overall_confidence}

| Concern | Investigation | Result | Confidence |
|---------|---------------|--------|------------|
"""

for finding in revision_findings:
    result_brief = str(finding['result'])[:50] + '...' if len(str(finding['result'])) > 50 else finding['result']
    revision_section += f"| {finding['concern'][:30]}... | {finding['investigation']} | {result_brief} | {finding['confidence']} |\n"

# Append to existing report
with open(existing_report_path, 'a') as f:
    f.write(revision_section)
```

### 7.5.5 Return Structured Result

```python
# Return to Researcher with structured result
return f"""
**Revision Summary:**
- Concerns addressed: {len(revision_findings)}
- Findings: {', '.join([f['investigation'] for f in revision_findings])}
- Confidence: {overall_confidence}
- Recommendation: {recommendation}

**Details:**
See DATA_REPORT.md "## Revision: Iteration {analysis_mode['iteration']}" section.
"""
```
```
  </action>
  <verify>grep -A 10 "Step 7.5: Focused Revision Analysis" agents/grd-explorer.md</verify>
  <done>grd-explorer.md has Step 7.5 for focused revision analysis that investigates concerns, appends to DATA_REPORT.md, and returns proceed/critical_issue recommendation</done>
</task>

<task type="auto">
  <name>Task 3: Update STATE.md template with Data Revisions table</name>
  <files>get-research-done/templates/state.md</files>
  <action>
In get-research-done/templates/state.md, locate the "### Data Revisions" section in the template.

The section currently exists but verify it has the correct structure. Update it to:

```markdown
### Data Revisions

Track REVISE_DATA cycles within current hypothesis:

| Iteration | Concerns | Explorer Result | Action Taken |
|-----------|----------|-----------------|--------------|
| {{N}} | {{concern_list}} | {{result_summary}} | {{action}} |

**Data Revision Limits:**
- Current count: {{data_revision_count}} of {{data_revision_limit}}
- If limit reached: Escalate to human (data quality may be insufficient for hypothesis)
```

Also ensure the Research Loop State section has a field for tracking data revision count. Find "### Current Iteration" and add:

```markdown
- **Data Revisions:** {{data_revision_count}} of {{data_revision_limit}} (default limit: 2)
```

In the `<sections>` explanation area, add documentation for the Data Revisions table:

```markdown
### Data Revisions Table

Tracks REVISE_DATA cycles within the current hypothesis:
- **Iteration**: Which experiment iteration triggered data revision
- **Concerns**: Summary of data concerns from Critic (truncated)
- **Explorer Result**: Outcome of re-analysis (addressed, critical issue, etc.)
- **Action Taken**: What happened next (loop continues, escalated, etc.)

Data revisions are tracked separately from method revisions because:
- Data issues are more fundamental than hyperparameter tuning
- Lower limit (default 2) prevents infinite data loops
- Multiple data revisions suggest hypothesis may not be viable with current data
```
  </action>
  <verify>grep -A 10 "### Data Revisions" get-research-done/templates/state.md</verify>
  <done>STATE.md template has Data Revisions table with Iteration, Concerns, Explorer Result, and Action Taken columns, plus data revision count tracking and documentation</done>
</task>

</tasks>

<verification>
1. Verify Explorer has mode detection:
   ```bash
   grep -c "analysis_mode" agents/grd-explorer.md
   ```
   Expected: 5+ occurrences

2. Verify Explorer has revision analysis workflow:
   ```bash
   grep "Step 7.5" agents/grd-explorer.md
   ```
   Expected: Match found

3. Verify Explorer returns structured recommendation:
   ```bash
   grep "Recommendation:" agents/grd-explorer.md
   ```
   Expected: Found in revision output format

4. Verify STATE.md template has Data Revisions:
   ```bash
   grep "Data Revisions" get-research-done/templates/state.md
   ```
   Expected: Multiple matches (section and documentation)

5. Verify append-only pattern in Explorer:
   ```bash
   grep "Revision: Iteration" agents/grd-explorer.md
   ```
   Expected: Match found in revision section format
</verification>

<success_criteria>
- [ ] grd-explorer.md has Step 0 for mode detection (initial vs revision)
- [ ] grd-explorer.md extracts concerns from spawn prompt in revision mode
- [ ] grd-explorer.md has Step 7.5 for focused revision analysis
- [ ] Step 7.5 investigates only flagged concerns (not full re-profiling)
- [ ] Step 7.5 appends "## Revision: Iteration N" to DATA_REPORT.md (preserves original)
- [ ] Step 7.5 returns structured recommendation (proceed/critical_issue)
- [ ] STATE.md template has Data Revisions table with proper columns
- [ ] STATE.md template has data revision count tracking in Current Iteration section
- [ ] STATE.md template has documentation for Data Revisions table
</success_criteria>

<output>
After completion, create `.planning/phases/07-revise-data-auto-routing/07-02-SUMMARY.md`
</output>
