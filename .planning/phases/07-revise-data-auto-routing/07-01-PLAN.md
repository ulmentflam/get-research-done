---
phase: 07-revise-data-auto-routing
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - agents/grd-researcher.md
autonomous: true

must_haves:
  truths:
    - "When Critic returns REVISE_DATA verdict, Researcher auto-spawns Explorer via Task tool"
    - "Explorer spawn includes extracted concerns from CRITIC_LOG.md"
    - "After Explorer completes, Researcher auto-continues loop without user intervention"
    - "Data revision limit (default 2) prevents infinite REVISE_DATA cycles"
  artifacts:
    - path: "agents/grd-researcher.md"
      provides: "REVISE_DATA auto-routing logic in Step 7.6"
      contains: "Task(prompt=.*subagent_type=\"grd-explorer\""
  key_links:
    - from: "agents/grd-researcher.md"
      to: "agents/grd-explorer.md"
      via: "Task tool spawn with concerns"
      pattern: "subagent_type=\"grd-explorer\""
---

<objective>
Update grd-researcher.md Step 7.6 to auto-spawn Explorer on REVISE_DATA verdict

Purpose: Close the integration gap between Critic and Explorer - currently REVISE_DATA requires manual user intervention to route back to /grd:explore. This plan automates that routing to complete the fully autonomous recursive loop.

Output: Modified grd-researcher.md with auto-spawn logic in Step 7.6 that extracts concerns from Critic feedback, spawns Explorer via Task tool, and auto-continues the research loop.
</objective>

<execution_context>
@/Users/evanowen/.claude/get-shit-done/workflows/execute-plan.md
@/Users/evanowen/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-revise-data-auto-routing/07-RESEARCH.md
@agents/grd-researcher.md
@agents/grd-explorer.md
@agents/grd-critic.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add data revision tracking variables to grd-researcher internal state</name>
  <files>agents/grd-researcher.md</files>
  <action>
In grd-researcher.md, locate the "### Internal State" section under `<role>`.

Add data revision tracking variables after the existing state variables:

```markdown
- data_revision_count: Number of REVISE_DATA cycles in current hypothesis (starts at 0)
- data_revision_limit: Maximum allowed data revisions (default: 2, separate from iteration_limit)
- data_revision_history: List of data concerns addressed
```

This enables tracking data revisions separately from method revisions (per RESEARCH.md recommendation).
  </action>
  <verify>grep -A 5 "data_revision" agents/grd-researcher.md</verify>
  <done>grd-researcher.md has data_revision_count, data_revision_limit, and data_revision_history variables in Internal State section</done>
</task>

<task type="auto">
  <name>Task 2: Implement auto-spawn Explorer logic in Step 7.6 REVISE_DATA route</name>
  <files>agents/grd-researcher.md</files>
  <action>
In grd-researcher.md, locate "#### Route: REVISE_DATA" section (currently shows manual routing instructions).

Replace the entire REVISE_DATA route section with the following auto-spawn implementation:

```markdown
#### Route: REVISE_DATA

1. **Check data revision limit:**
   ```python
   if data_revision_count >= data_revision_limit:
       # Too many data revisions - escalate to human
       return escalate_to_human(
           reason="data_revision_limit",
           message=f"Data quality concerns persist after {data_revision_count} revisions. Hypothesis may not be viable with current data.",
           evidence={
               'data_revision_count': data_revision_count,
               'concerns_addressed': data_revision_history
           }
       )
   ```

2. **Extract data concerns from Critic feedback:**
   ```python
   def extract_data_concerns(weaknesses: list, recommendations: list) -> list:
       """Extract data-specific concerns from Critic feedback."""
       data_keywords = [
           'leakage', 'leak', 'data quality', 'distribution', 'drift',
           'feature', 'correlation', 'train-test', 'overlap', 'imbalance',
           'missing', 'outlier', 'anomaly', 'temporal', 'target'
       ]

       concerns = []

       # Check weaknesses for data-related issues
       for weakness in weaknesses:
           if any(keyword in weakness.lower() for keyword in data_keywords):
               concerns.append(weakness)

       # Check recommendations for data investigation requests
       for rec in recommendations:
           if any(keyword in rec.lower() for keyword in data_keywords):
               concerns.append(rec)

       return list(set(concerns))  # Deduplicate

   data_concerns = extract_data_concerns(weaknesses, recommendations)
   ```

3. **Format investigation scope for Explorer:**
   ```python
   def format_investigation_scope(concerns: list) -> str:
       """Format concerns into Explorer investigation scope."""
       scope_items = []
       for concern in concerns:
           if 'leakage' in concern.lower():
               scope_items.append(f"- Re-run leakage detection for mentioned features")
           elif 'distribution' in concern.lower():
               scope_items.append(f"- Analyze distribution shift in flagged columns")
           elif 'train-test' in concern.lower() or 'overlap' in concern.lower():
               scope_items.append(f"- Verify train-test split integrity")
           elif 'missing' in concern.lower():
               scope_items.append(f"- Re-analyze missing data patterns")
           else:
               scope_items.append(f"- Investigate: {concern}")
       return "\n".join(scope_items)

   investigation_scope = format_investigation_scope(data_concerns)
   concerns_list = "\n".join([f"- {c}" for c in data_concerns])
   ```

4. **Auto-spawn Explorer via Task tool:**
   ```python
   explorer_result = Task(prompt=f"""
<context>
@.planning/DATA_REPORT.md
@experiments/run_{run_num}_{description}/CRITIC_LOG.md

Critic identified potential data quality issues during experiment validation.
This is a targeted re-analysis, not initial EDA.
Iteration: {iteration}
</context>

<concerns>
{concerns_list}
</concerns>

<instructions>
Re-analyze the dataset with focus on these specific concerns from the Critic.

Investigation scope:
{investigation_scope}

**Important:**
- This is a REVISION, not initial exploration
- Append findings to DATA_REPORT.md under "## Revision: Iteration {iteration}" section
- DO NOT overwrite original DATA_REPORT.md sections
- Focus only on the flagged concerns, not full re-profiling

After investigation, return:
- Updated findings for each concern
- Confidence level (HIGH/MEDIUM/LOW)
- Recommendation: "proceed" (continue loop) OR "critical_issue" (escalate to human)
</instructions>

<output>
Append revision section to DATA_REPORT.md and return structured result:

**Revision Summary:**
- Concerns addressed: [list]
- Findings: [brief per concern]
- Confidence: [HIGH/MEDIUM/LOW]
- Recommendation: [proceed/critical_issue]
</output>
""", subagent_type="grd-explorer", model="sonnet", description=f"Re-analyze data with targeted concerns (iteration {iteration})")
   ```

5. **Parse Explorer result and determine continuation:**
   ```python
   # Parse Explorer result for recommendation
   if "critical_issue" in explorer_result.lower():
       # Explorer found fundamental problem - escalate to human
       return escalate_to_human(
           reason="explorer_critical_issue",
           message="Explorer found critical data issue during re-analysis",
           evidence={
               'explorer_result': explorer_result,
               'concerns_investigated': data_concerns
           }
       )
   else:
       # Explorer recommends proceeding - auto-continue loop
       # Increment data revision count
       data_revision_count += 1
       data_revision_history.append({
           'iteration': iteration,
           'concerns': data_concerns,
           'result': 'addressed'
       })

       # Log to STATE.md (handled in Step 7.7)
       log_data_revision_to_state(iteration, data_concerns, explorer_result)

       # Auto-continue: Return to Step 2 (Create Run Directory) with new iteration
       # Include Explorer findings as additional context
       return continue_research_loop(
           iteration=iteration + 1,
           context={
               'data_revised': True,
               'revision_summary': explorer_result,
               'previous_critique': critique
           }
       )
   ```

6. **Update run README with REVISE_DATA status:**
   ```python
   update_readme_field("status", "data_revision_in_progress")
   update_readme_field("verdict", "REVISE_DATA")
   update_readme_field("data_concerns", data_concerns)
   ```
```

Remove the old manual routing instructions that said "user must manually route to /grd:explore".
  </action>
  <verify>grep -A 30 "Route: REVISE_DATA" agents/grd-researcher.md | head -50</verify>
  <done>grd-researcher.md Step 7.6 REVISE_DATA route auto-spawns Explorer via Task tool with extracted concerns, parses result, and auto-continues loop (no manual user routing)</done>
</task>

<task type="auto">
  <name>Task 3: Add log_data_revision_to_state helper in Step 7.7</name>
  <files>agents/grd-researcher.md</files>
  <action>
In grd-researcher.md, locate "### 7.7 Update README.md with Final Status" section.

Add a new subsection before it titled "### 7.6.1 Log Data Revision to STATE.md" with the following:

```markdown
### 7.6.1 Log Data Revision to STATE.md

**When REVISE_DATA triggers Explorer spawn, update STATE.md:**

```python
def log_data_revision_to_state(iteration: int, concerns: list, explorer_result: str):
    """Append data revision entry to STATE.md Data Revisions table."""
    state_md_path = '.planning/STATE.md'

    # Read current STATE.md
    with open(state_md_path, 'r') as f:
        state_content = f.read()

    # Format concerns for table (truncate if too long)
    concerns_summary = ', '.join(concerns[:2])
    if len(concerns) > 2:
        concerns_summary += f'... (+{len(concerns)-2} more)'

    # Extract result summary
    if 'critical_issue' in explorer_result.lower():
        result_summary = 'Critical issue found - escalated'
    elif 'proceed' in explorer_result.lower():
        result_summary = 'Addressed - loop continues'
    else:
        result_summary = 'Completed'

    # Format as markdown table row
    revision_entry = f"| {iteration} | {concerns_summary} | {result_summary} |"

    # Find Data Revisions table and append
    if '### Data Revisions' in state_content:
        # Find the table and append row
        lines = state_content.split('\n')
        insert_index = None
        for i, line in enumerate(lines):
            if '### Data Revisions' in line:
                # Find the end of the table (next section or empty lines)
                for j in range(i+1, len(lines)):
                    if lines[j].startswith('##') or (lines[j].strip() == '' and j > i+4):
                        insert_index = j
                        break
                break

        if insert_index:
            lines.insert(insert_index, revision_entry)
            state_content = '\n'.join(lines)
    else:
        # Add Data Revisions section if missing
        data_revisions_section = f"""
### Data Revisions

| Iteration | Concerns | Explorer Result |
|-----------|----------|-----------------|
{revision_entry}
"""
        # Insert after Loop History section
        if '### Loop History' in state_content:
            state_content = state_content.replace(
                '### Loop History',
                f'### Loop History\n\n{data_revisions_section}\n'
            )
        else:
            state_content += f'\n{data_revisions_section}'

    # Write updated STATE.md
    with open(state_md_path, 'w') as f:
        f.write(state_content)
```

**This ensures data revision events are tracked in STATE.md for audit trail and loop analysis.**
```
  </action>
  <verify>grep -A 20 "Log Data Revision to STATE" agents/grd-researcher.md</verify>
  <done>grd-researcher.md has log_data_revision_to_state helper that updates STATE.md Data Revisions table</done>
</task>

</tasks>

<verification>
1. Verify grd-researcher.md has data_revision_count, data_revision_limit variables:
   ```bash
   grep -c "data_revision" agents/grd-researcher.md
   ```
   Expected: 10+ occurrences

2. Verify REVISE_DATA route has Task spawning:
   ```bash
   grep "subagent_type=\"grd-explorer\"" agents/grd-researcher.md
   ```
   Expected: Match found in REVISE_DATA section

3. Verify manual routing instructions removed:
   ```bash
   grep -c "user must manually route" agents/grd-researcher.md || echo "Not found (good)"
   ```
   Expected: 0 or "Not found"

4. Verify STATE.md logging helper exists:
   ```bash
   grep "log_data_revision_to_state" agents/grd-researcher.md
   ```
   Expected: Function definition found
</verification>

<success_criteria>
- [ ] grd-researcher.md has data revision tracking variables (count, limit, history)
- [ ] Step 7.6 REVISE_DATA route auto-spawns Explorer via Task tool
- [ ] Explorer spawn includes formatted concerns from Critic feedback
- [ ] Explorer result parsed for proceed/critical_issue recommendation
- [ ] On proceed: loop auto-continues to new iteration without user intervention
- [ ] On critical_issue: escalates to human with evidence
- [ ] Data revision limit (default 2) enforced before spawn
- [ ] STATE.md logging helper tracks data revision events
- [ ] No manual routing instructions remain ("user must manually route")
</success_criteria>

<output>
After completion, create `.planning/phases/07-revise-data-auto-routing/07-01-SUMMARY.md`
</output>
