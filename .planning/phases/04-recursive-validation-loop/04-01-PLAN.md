---
phase: 04-recursive-validation-loop
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - commands/grd/research.md
  - agents/grd-researcher.md
  - get-research-done/templates/experiment-readme.md
autonomous: true

must_haves:
  truths:
    - "User can run /grd:research to start experiment implementation"
    - "Researcher agent can read OBJECTIVE.md and understand what to implement"
    - "Each experiment iteration creates isolated run_NNN directory"
  artifacts:
    - path: "commands/grd/research.md"
      provides: "Research command entry point"
      min_lines: 100
    - path: "agents/grd-researcher.md"
      provides: "Researcher agent with implementation workflow"
      min_lines: 200
    - path: "get-research-done/templates/experiment-readme.md"
      provides: "Template for run README.md files"
      min_lines: 30
  key_links:
    - from: "commands/grd/research.md"
      to: "agents/grd-researcher.md"
      via: "agent spawn"
      pattern: "grd-researcher"
    - from: "agents/grd-researcher.md"
      to: ".planning/OBJECTIVE.md"
      via: "file read"
      pattern: "OBJECTIVE.md"
---

<objective>

Create the `/grd:research` command and grd-researcher agent that implements experiments from OBJECTIVE.md with proper experiment isolation.

Purpose: Researcher is the implementation engine of the recursive validation loop. It reads OBJECTIVE.md to understand what hypothesis to test, implements experiments (Python scripts or notebooks), and produces artifacts in isolated run_NNN directories for reproducibility.

Output:
- `/grd:research` command file
- grd-researcher agent with implementation workflow
- Experiment README template for run documentation

</objective>

<execution_context>

@/Users/evanowen/.claude/get-research-done/workflows/execute-plan.md
@/Users/evanowen/.claude/get-research-done/templates/summary.md

</execution_context>

<context>

@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-recursive-validation-loop/04-CONTEXT.md
@.planning/phases/04-recursive-validation-loop/04-RESEARCH.md

Reference existing patterns:
@commands/grd/explore.md
@commands/grd/architect.md
@agents/grd-explorer.md
@agents/grd-architect.md

</context>

<tasks>

<task type="auto">
  <name>Task 1: Create /grd:research command</name>
  <files>commands/grd/research.md</files>
  <action>
Create the research command file following the established pattern from explore.md and architect.md.

Structure:
```markdown
# /grd:research

**Implements experiments from OBJECTIVE.md with iterative validation (Phase 4 command)**

---
name: grd:research
description: Implement experiments from hypothesis with iterative validation loop
allowed-tools: [Read, Bash, Write, Task, AskUserQuestion]
agent: grd-researcher
phase: 4
requires: [OBJECTIVE.md]
produces: [experiments/run_NNN/]
---
```

Include:
1. Objective section explaining this is Phase 4 experiment implementation
2. Execution context referencing templates
3. Process section with 4 phases:
   - Phase 1: Setup - check OBJECTIVE.md exists (hard gate), determine run number
   - Phase 2: Spawn Researcher - pass OBJECTIVE.md context, critique history if exists
   - Phase 3: Wait for Critic - command doesn't spawn Critic directly, Researcher does via Task
   - Phase 4: Present Results - show experiment status, path to run directory
4. Arguments section:
   - [description] - optional one-line description for run naming (e.g., "baseline", "lr_sweep")
   - --continue - continue from previous run with Critic feedback
   - --iteration N - specify iteration number manually
5. Examples showing different invocation patterns
6. Output section describing experiments/run_NNN/ structure
7. Success criteria checklist

Key behaviors:
- Hard gate on OBJECTIVE.md (required, unlike DATA_REPORT.md soft gate)
- Auto-increment run number by scanning experiments/ directory
- Pass critique history to Researcher if continuing from REVISE_METHOD
- Display banner with run number and OBJECTIVE.md hypothesis summary
  </action>
  <verify>
```bash
# File exists with correct structure
test -f commands/grd/research.md && echo "Command file exists"

# Has required sections
grep -q "name: grd:research" commands/grd/research.md && echo "Has frontmatter"
grep -q "agent: grd-researcher" commands/grd/research.md && echo "References researcher agent"
grep -q "OBJECTIVE.md" commands/grd/research.md && echo "References OBJECTIVE.md"
grep -q "experiments/run_" commands/grd/research.md && echo "References run directories"
```
  </verify>
  <done>Command file exists with frontmatter, process phases, arguments, examples, and references to grd-researcher agent and OBJECTIVE.md</done>
</task>

<task type="auto">
  <name>Task 2: Create grd-researcher agent</name>
  <files>agents/grd-researcher.md</files>
  <action>
Create the researcher agent following established patterns from grd-explorer.md and grd-architect.md.

Structure:
```markdown
---
name: grd-researcher
description: Implements experiments from OBJECTIVE.md hypothesis with code generation and artifact management
tools: Read, Write, Bash, Glob, Grep, Task
color: green
---
```

Include:
1. Role section explaining Researcher implements experiments from OBJECTIVE.md
2. Execution flow with 8 steps:

**Step 1: Load Context**
- Read OBJECTIVE.md, extract: hypothesis, success metrics, evaluation methodology, baselines, constraints
- Read DATA_REPORT.md if referenced in OBJECTIVE.md
- Parse previous CRITIC_LOG if continuing from REVISE_METHOD
- Determine run number from arguments or auto-increment

**Step 2: Create Run Directory**
- Create experiments/run_{NNN}_{description}/ with subdirectories:
  - code/ (experiment scripts)
  - data/ (symlinks/references)
  - logs/ (training output)
  - outputs/ (model artifacts)
  - metrics/ (SCORECARD.json goes here)
- Generate README.md from template with experiment summary

**Step 3: Reference Data**
- Create data references (not copies) with hashes for provenance
- Use hashlib SHA-256 for file hashing
- Create .ref files pointing to data location with hash

**Step 4: Generate Experiment Code**
- Based on OBJECTIVE.md hypothesis, generate train.py or experiment.ipynb
- Include config.yaml with hyperparameters
- Ensure code is self-contained and reproducible
- Include random seed from OBJECTIVE.md evaluation.random_state

**Step 5: Execute Experiment** (or prepare for user execution)
- If simple enough, run experiment directly via Bash
- If complex (GPU, long-running), prepare instructions for user
- Capture stdout/stderr to logs/training.log

**Step 6: Collect Metrics**
- Parse experiment output for metrics
- Compare against OBJECTIVE.md success criteria
- Prepare metrics dict for Critic

**Step 7: Spawn Critic**
- Use Task to spawn grd-critic agent
- Pass: experiment code, metrics, OBJECTIVE.md criteria, previous critiques
- Await verdict: PROCEED, REVISE_METHOD, REVISE_DATA, ESCALATE

**Step 8: Handle Verdict**
- PROCEED: Return success, Critic will spawn Evaluator
- REVISE_METHOD: Save CRITIC_LOG.md, return for another iteration
- REVISE_DATA: Route back to /grd:explore with specific concerns
- ESCALATE: Surface to human for decision

3. Quality gates section
4. Success criteria checklist
5. Example interactions showing iteration flow

Key behaviors from CONTEXT.md:
- Both Python scripts and Jupyter notebooks supported
- Config file recommended (config.yaml)
- Brief README.md in each run
- Full snapshot: code, data refs, configs, logs, outputs
  </action>
  <verify>
```bash
# File exists with correct structure
test -f agents/grd-researcher.md && echo "Agent file exists"

# Has required sections
grep -q "name: grd-researcher" agents/grd-researcher.md && echo "Has frontmatter"
grep -q "Step 1:" agents/grd-researcher.md && echo "Has step 1"
grep -q "Step 8:" agents/grd-researcher.md && echo "Has step 8"
grep -q "OBJECTIVE.md" agents/grd-researcher.md && echo "References OBJECTIVE.md"
grep -q "grd-critic" agents/grd-researcher.md && echo "References Critic agent"
grep -q "run_" agents/grd-researcher.md && echo "References run directories"
```
  </verify>
  <done>Agent file exists with 8-step workflow covering context loading, directory creation, data referencing, code generation, execution, metrics collection, Critic spawning, and verdict handling</done>
</task>

<task type="auto">
  <name>Task 3: Create experiment README template</name>
  <files>get-research-done/templates/experiment-readme.md</files>
  <action>
Create a template for the README.md file generated in each run directory.

Structure:
```markdown
# {{run_name}}

**Created:** {{timestamp}}
**Iteration:** {{iteration_number}}
**Status:** {{pending|complete|archived}}
**Hypothesis:** {{brief_hypothesis_from_objective}}

## Summary

{{one_paragraph_explaining_what_why_how}}

## Reproduce

\`\`\`bash
cd experiments/{{run_name}}
python code/train.py --config config.yaml
\`\`\`

## Configuration

See: `config.yaml`

Key parameters:
{{key_hyperparameters_list}}

## Data

- Source: {{data_path}}
- Hash: {{data_hash}}
- Version: {{data_version_if_available}}

## Results

{{metrics_summary_or_pending}}

## Critic Verdict

{{verdict_if_available_or_pending}}

---
*Generated by grd-researcher*
```

Include placeholders for:
- Run metadata (name, timestamp, iteration)
- Experiment summary (brief what/why/how)
- Reproduction instructions
- Configuration reference
- Data provenance (path, hash)
- Results (metrics or "pending")
- Critic verdict (if available)
  </action>
  <verify>
```bash
# File exists
test -f get-research-done/templates/experiment-readme.md && echo "Template exists"

# Has required placeholders
grep -q "{{run_name}}" get-research-done/templates/experiment-readme.md && echo "Has run_name placeholder"
grep -q "{{timestamp}}" get-research-done/templates/experiment-readme.md && echo "Has timestamp placeholder"
grep -q "Reproduce" get-research-done/templates/experiment-readme.md && echo "Has reproduce section"
grep -q "{{data_hash}}" get-research-done/templates/experiment-readme.md && echo "Has data hash placeholder"
```
  </verify>
  <done>Template exists with placeholders for run metadata, summary, reproduction instructions, configuration, data provenance, results, and Critic verdict</done>
</task>

</tasks>

<verification>

After all tasks complete:
1. `/grd:research` command file exists with correct frontmatter
2. grd-researcher agent has complete 8-step workflow
3. Experiment README template has all required sections
4. Command references agent correctly
5. Agent references OBJECTIVE.md and Critic agent
6. Directory structure pattern (run_NNN) documented

</verification>

<success_criteria>

- [ ] Command file at commands/grd/research.md with frontmatter and process
- [ ] Agent file at agents/grd-researcher.md with 8-step execution flow
- [ ] Template at get-research-done/templates/experiment-readme.md
- [ ] Command spawns grd-researcher agent
- [ ] Agent reads OBJECTIVE.md for hypothesis context
- [ ] Agent creates isolated run_NNN directories
- [ ] Agent references data with hashes (not copies)
- [ ] Agent spawns grd-critic for validation

</success_criteria>

<output>

After completion, create `.planning/phases/04-recursive-validation-loop/04-01-SUMMARY.md`

</output>
