---
phase: 09-hardware-profiling-long-running
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/grd/experiment/__init__.py
  - src/grd/experiment/timeout_manager.py
  - src/grd/experiment/checkpoint_handler.py
autonomous: true

must_haves:
  truths:
    - "Timeout manager provides session-level approval for long-running experiments"
    - "Checkpoint handler saves and loads complete training state"
    - "Training can be interrupted and resumed without losing progress"
    - "User can resume experiments from last checkpoint"
  artifacts:
    - path: "src/grd/experiment/timeout_manager.py"
      provides: "ExperimentTimeoutManager with session-level approval"
      exports: ["ExperimentTimeoutManager"]
    - path: "src/grd/experiment/checkpoint_handler.py"
      provides: "CheckpointHandler for save/load/resume"
      exports: ["CheckpointHandler"]
    - path: "src/grd/experiment/__init__.py"
      provides: "Package exports"
      contains: "from .timeout_manager import"
  key_links:
    - from: "src/grd/experiment/checkpoint_handler.py"
      to: "torch"
      via: "torch.save and torch.load for checkpoints"
      pattern: "torch\\.save"
---

<objective>
Create the timeout management and checkpoint handling modules that enable long-running ML experiments to bypass standard timeouts and recover from interruptions.

Purpose: ML training often exceeds the 10-minute task timeout. Session-level approval allows experiments to run without repeated prompts. Checkpoints ensure training can resume after interruption.

Output: Two Python modules (timeout_manager.py, checkpoint_handler.py) in src/grd/experiment/ for use by Researcher agent.
</objective>

<execution_context>
@/Users/evanowen/.claude/get-shit-done/workflows/execute-plan.md
@/Users/evanowen/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-hardware-profiling-long-running/09-RESEARCH.md
@src/grd/__init__.py
@src/grd/notebook_executor.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create timeout manager module</name>
  <files>src/grd/experiment/__init__.py, src/grd/experiment/timeout_manager.py</files>
  <action>
Create src/grd/experiment/ directory and implement the timeout management module.

1. Create src/grd/experiment/__init__.py with exports:
   ```python
   from .timeout_manager import ExperimentTimeoutManager
   from .checkpoint_handler import CheckpointHandler
   ```

2. Create src/grd/experiment/timeout_manager.py implementing:

   ExperimentTimeoutManager class with:
   - __init__(self, default_timeout: int = 600) - sets default 10-min timeout
   - long_running_approved: bool = False - session-level flag
   - session_timeout: int | None - None means no timeout
   - approval_metadata: dict - tracks when/why approved for audit

   Methods:
   - request_long_running_approval(estimated_minutes: float) -> bool
     - If already approved, return True immediately
     - Print estimated duration and timeout warning
     - Return True (approval granted) - DO NOT use input() as this is for agent context
     - Set long_running_approved = True
     - Log approval in approval_metadata with timestamp

   - get_timeout(estimated_seconds: float) -> int | None
     - If estimated_seconds <= 600: return default_timeout
     - If long_running_approved: return None (no timeout)
     - Else: return default_timeout

   - reset_approval() -> None
     - Reset long_running_approved to False
     - Clear session_timeout

   - get_approval_metadata() -> dict
     - Return audit trail of approvals

Important: The manager does NOT use asyncio - it provides configuration for external timeout handling. The actual timeout is applied by subprocess.run(timeout=X) or similar in the caller.
  </action>
  <verify>
Run:
```python
from src.grd.experiment import ExperimentTimeoutManager
tm = ExperimentTimeoutManager()
assert tm.get_timeout(300) == 600  # Short experiment gets default
tm.request_long_running_approval(30)  # 30 minutes
assert tm.long_running_approved == True
assert tm.get_timeout(3600) is None  # No timeout after approval
print("All checks passed")
```
  </verify>
  <done>
ExperimentTimeoutManager provides session-level approval tracking, get_timeout() returns appropriate value based on approval state, approval_metadata captures audit trail.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create checkpoint handler module</name>
  <files>src/grd/experiment/checkpoint_handler.py</files>
  <action>
Create src/grd/experiment/checkpoint_handler.py implementing checkpoint save/load with graceful shutdown.

1. CheckpointHandler class:
   ```python
   class CheckpointHandler:
       def __init__(self, checkpoint_dir: Path):
           self.checkpoint_dir = Path(checkpoint_dir)
           self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
           self.interrupted = False
           self._setup_signal_handlers()
   ```

2. Implement _setup_signal_handlers():
   - Register SIGINT and SIGTERM handlers (Pattern 7 from RESEARCH.md)
   - Set self.interrupted = True when signal received
   - Print warning about graceful shutdown in progress

3. Implement save_checkpoint():
   ```python
   def save_checkpoint(
       self,
       epoch: int,
       model_state: dict,  # model.state_dict()
       optimizer_state: dict,  # optimizer.state_dict()
       loss: float,
       metadata: dict = None
   ) -> Path:
   ```
   - Creates checkpoint dict with epoch, model_state, optimizer_state, loss, metadata
   - Saves as checkpoint_epoch_{N}.pt AND checkpoint_latest.pt
   - Uses torch.save() for atomic writes
   - Returns path to saved checkpoint

4. Implement load_checkpoint():
   ```python
   def load_checkpoint(self) -> dict | None:
   ```
   - Loads checkpoint_latest.pt if exists
   - Returns dict with epoch, model_state, optimizer_state, loss, metadata
   - Returns None if no checkpoint exists

5. Implement find_latest_checkpoint() -> Path | None:
   - Finds checkpoint with highest epoch number
   - Returns path or None

6. Implement check_interrupted() -> bool:
   - Returns self.interrupted flag
   - Used in training loops to detect shutdown request

7. Implement get_resumability_hints() -> dict:
   - Returns suggestions for resuming training
   - Includes: has_checkpoint, latest_epoch, checkpoint_path, estimated_remaining_epochs
  </action>
  <verify>
Run:
```python
from src.grd.experiment import CheckpointHandler
from pathlib import Path
import tempfile

with tempfile.TemporaryDirectory() as td:
    ch = CheckpointHandler(Path(td))
    ch.save_checkpoint(
        epoch=5,
        model_state={"weights": [1,2,3]},
        optimizer_state={"lr": 0.001},
        loss=0.5,
        metadata={"run_id": "test"}
    )
    loaded = ch.load_checkpoint()
    assert loaded["epoch"] == 5
    assert loaded["loss"] == 0.5
    hints = ch.get_resumability_hints()
    assert hints["has_checkpoint"] == True
    print("All checks passed")
```
  </verify>
  <done>
CheckpointHandler saves complete training state, loads checkpoint for resume, signal handlers set interrupted flag, get_resumability_hints() provides actionable guidance.
  </done>
</task>

</tasks>

<verification>
1. Both modules import without errors: `python -c "from src.grd.experiment import *"`
2. Timeout manager tracks approval state correctly
3. Checkpoint handler saves/loads complete state
4. Signal handlers registered without errors
5. Checkpoint files use .pt extension and atomic writes
</verification>

<success_criteria>
- [ ] src/grd/experiment/__init__.py exports all public classes
- [ ] ExperimentTimeoutManager provides session-level approval tracking
- [ ] get_timeout() returns None after approval for long-running experiments
- [ ] CheckpointHandler saves model_state, optimizer_state, epoch, loss, metadata
- [ ] load_checkpoint() restores complete training state
- [ ] Signal handlers set interrupted flag on SIGINT/SIGTERM
- [ ] get_resumability_hints() provides actionable guidance
</success_criteria>

<output>
After completion, create `.planning/phases/09-hardware-profiling-long-running/09-02-SUMMARY.md`
</output>
