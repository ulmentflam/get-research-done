---
phase: 09-hardware-profiling-long-running
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/grd/hardware/__init__.py
  - src/grd/hardware/profiler.py
  - src/grd/hardware/estimator.py
autonomous: true

must_haves:
  truths:
    - "Hardware profile captures CPU, memory, disk, and GPU specs"
    - "Duration estimation provides time estimate for experiments"
    - "GPU detection works with PyTorch (preferred) or GPUtil fallback"
  artifacts:
    - path: "src/grd/hardware/profiler.py"
      provides: "HardwareProfiler class with capture_hardware_profile()"
      exports: ["capture_hardware_profile", "HardwareProfile"]
    - path: "src/grd/hardware/estimator.py"
      provides: "Duration estimation from hardware context"
      exports: ["estimate_training_duration", "DurationEstimate"]
    - path: "src/grd/hardware/__init__.py"
      provides: "Package exports"
      contains: "from .profiler import"
  key_links:
    - from: "src/grd/hardware/estimator.py"
      to: "src/grd/hardware/profiler.py"
      via: "imports HardwareProfile type"
      pattern: "from .profiler import"
---

<objective>
Create the hardware profiling and duration estimation modules that enable reproducible ML experiments by capturing hardware context.

Purpose: Hardware context (GPU model, CUDA version, CPU cores, RAM, disk) is essential for reproducing ML experiments. Duration estimates allow the system to determine if experiments will exceed standard timeouts.

Output: Two Python modules (profiler.py, estimator.py) in src/grd/hardware/ that can be imported by Explorer and Researcher agents.
</objective>

<execution_context>
@/Users/evanowen/.claude/get-shit-done/workflows/execute-plan.md
@/Users/evanowen/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-hardware-profiling-long-running/09-RESEARCH.md
@src/grd/__init__.py
@src/grd/notebook_executor.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create hardware profiler module</name>
  <files>src/grd/hardware/__init__.py, src/grd/hardware/profiler.py</files>
  <action>
Create src/grd/hardware/ directory and implement the hardware profiling module.

1. Create src/grd/hardware/__init__.py with exports:
   ```python
   from .profiler import capture_hardware_profile, HardwareProfile
   from .estimator import estimate_training_duration, DurationEstimate
   ```

2. Create src/grd/hardware/profiler.py implementing:
   - HardwareProfile TypedDict with cpu, memory, disk, gpu, timestamp fields
   - capture_hardware_profile() function that:
     - Uses psutil for CPU cores, frequency, memory, disk
     - Uses py-cpuinfo for CPU brand and architecture
     - Uses torch.cuda (preferred) for GPU detection, falls back to GPUtil
     - Handles no-GPU case gracefully (gpu: None)
     - Returns HardwareProfile dict

Follow the Pattern 1 code from RESEARCH.md exactly. Key implementation notes:
- psutil.cpu_count(logical=False) for physical cores
- torch.cuda.get_device_properties(0) for GPU info
- GPUtil.getGPUs() as fallback when PyTorch unavailable
- Include timestamp in ISO format

Handle ImportError gracefully - if psutil/gputil/torch not installed, log warning and return partial profile.
  </action>
  <verify>
Run: `python -c "from src.grd.hardware import capture_hardware_profile; print(capture_hardware_profile())"`
Should output a dict with cpu, memory, disk, gpu (or None), timestamp fields.
  </verify>
  <done>
capture_hardware_profile() returns complete hardware profile dict, GPU detection works (or returns None if no GPU), no import errors on standard GRD setup.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create duration estimator module</name>
  <files>src/grd/hardware/estimator.py</files>
  <action>
Create src/grd/hardware/estimator.py implementing duration estimation.

1. Create DurationEstimate TypedDict with fields:
   - estimated_seconds: float
   - estimated_minutes: float
   - estimated_hours: float
   - is_long_running: bool (True if > 600 seconds)
   - requires_user_confirmation: bool (same as is_long_running)
   - gpu_tflops: float
   - confidence: str (HIGH/MEDIUM/LOW based on estimation method)

2. Implement estimate_training_duration() function:
   ```python
   def estimate_training_duration(
       num_samples: int,
       num_epochs: int,
       model_params: int,
       hardware_profile: dict,
       batch_size: int = 32
   ) -> DurationEstimate:
   ```

   - Use GPU TFLOPs lookup table from RESEARCH.md Pattern 2
   - Common GPUs: V100=7.0, A100=19.5, H100=60.0, T4=8.1
   - Default to 5.0 TFLOPs for unknown GPUs
   - Compute: 6 * params * samples * epochs (forward + backward)
   - Apply 50% efficiency factor (theoretical_seconds * 2)
   - is_long_running = estimated_seconds > 600
   - Confidence: HIGH if GPU in lookup table, MEDIUM otherwise, LOW if no GPU

3. Also implement simpler estimate_from_data_size() for EDA:
   ```python
   def estimate_eda_duration(
       num_rows: int,
       num_columns: int,
       hardware_profile: dict
   ) -> DurationEstimate:
   ```
   - Estimate based on row/column count and available memory
   - Simpler heuristic: ~10 rows/ms for profiling operations
  </action>
  <verify>
Run: `python -c "from src.grd.hardware import estimate_training_duration, capture_hardware_profile; h = capture_hardware_profile(); print(estimate_training_duration(100000, 10, 1000000, h))"`
Should output DurationEstimate dict with all fields populated.
  </verify>
  <done>
estimate_training_duration() returns complete estimate, is_long_running correctly flags experiments >10 minutes, confidence reflects GPU detection quality.
  </done>
</task>

</tasks>

<verification>
1. Both modules import without errors: `python -c "from src.grd.hardware import *"`
2. Hardware profile captures real system info (not mocked)
3. Duration estimate scales with inputs (more epochs = longer time)
4. No-GPU case handled gracefully
</verification>

<success_criteria>
- [ ] src/grd/hardware/__init__.py exports all public functions
- [ ] capture_hardware_profile() returns complete HardwareProfile
- [ ] GPU detection works with PyTorch or GPUtil fallback
- [ ] estimate_training_duration() returns DurationEstimate with is_long_running flag
- [ ] confidence field reflects estimation quality
- [ ] All functions handle missing dependencies gracefully
</success_criteria>

<output>
After completion, create `.planning/phases/09-hardware-profiling-long-running/09-01-SUMMARY.md`
</output>
