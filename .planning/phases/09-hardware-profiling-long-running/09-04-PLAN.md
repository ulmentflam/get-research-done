---
phase: 09-hardware-profiling-long-running
plan: 04
type: execute
wave: 3
depends_on: ["09-01", "09-02", "09-03"]
files_modified:
  - agents/grd-researcher.md
autonomous: true

must_haves:
  truths:
    - "Researcher estimates experiment duration before execution"
    - "Long-running experiments trigger session-level approval"
    - "Experiment metadata includes hardware context"
    - "Checkpoint hints provided for resumability"
  artifacts:
    - path: "agents/grd-researcher.md"
      provides: "Updated agent with duration estimation, timeout handling, checkpoint hints"
      contains: "estimate_training_duration"
  key_links:
    - from: "agents/grd-researcher.md"
      to: "src/grd/hardware/estimator.py"
      via: "imports estimate_training_duration"
      pattern: "from src.grd.hardware import"
    - from: "agents/grd-researcher.md"
      to: "src/grd/experiment/timeout_manager.py"
      via: "imports ExperimentTimeoutManager"
      pattern: "ExperimentTimeoutManager"
    - from: "agents/grd-researcher.md"
      to: "src/grd/experiment/checkpoint_handler.py"
      via: "imports CheckpointHandler"
      pattern: "CheckpointHandler"
    - from: "agents/grd-researcher.md"
      to: "templates/data-report.md"
      via: "reads hardware profile from DATA_REPORT.md"
      pattern: "parse_hardware_section"
---

<objective>
Update the Researcher agent to estimate experiment duration, handle long-running experiments with session-level approval, include hardware context in metadata, and provide checkpoint hints for resumability.

Purpose: This completes the Phase 9 loop by integrating hardware profiling (from Explorer) with experiment execution (in Researcher). Long-running experiments can now proceed without repeated prompts, and users get visibility into progress and recovery options.

Output: Updated grd-researcher.md agent with Step 1.6 (duration estimation), Step 5.0 (timeout handling), and Step 7.7 (checkpoint hints).
</objective>

<execution_context>
@/Users/evanowen/.claude/get-shit-done/workflows/execute-plan.md
@/Users/evanowen/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-hardware-profiling-long-running/09-RESEARCH.md
@.planning/phases/09-hardware-profiling-long-running/09-03-SUMMARY.md
@agents/grd-researcher.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add duration estimation step to Researcher agent</name>
  <files>agents/grd-researcher.md</files>
  <action>
Update agents/grd-researcher.md to add Step 1.6 for duration estimation after Step 1.5 (Detect Experiment Type).

1. Add new section after Step 1.5:

```markdown
## Step 1.6: Estimate Experiment Duration

**Responsibilities:**
- Load hardware profile from DATA_REPORT.md
- Estimate training duration based on model size and data
- Determine if experiment is long-running (>10 minutes)
- Request session-level approval if needed

### Duration Estimation

**Load hardware context from DATA_REPORT.md:**

```python
from src.grd.hardware import estimate_training_duration
from src.grd.experiment import ExperimentTimeoutManager
from pathlib import Path
import re

def parse_hardware_section(report_path: Path) -> dict | None:
    """Extract hardware profile from DATA_REPORT.md if available.

    Parses the Hardware Profile section and returns a dict matching
    the HardwareProfile structure expected by estimate_training_duration().

    Returns None if:
    - File doesn't exist
    - Hardware Profile section not found
    - Section contains placeholder text
    """
    if not report_path.exists():
        return None

    content = report_path.read_text()

    # Find Hardware Profile section
    hw_match = re.search(r'## Hardware Profile\s*\n(.*?)(?=\n## |\Z)', content, re.DOTALL)
    if not hw_match:
        return None

    hw_section = hw_match.group(1)

    # Check for placeholder
    if 'Hardware profile not captured' in hw_section:
        return None

    # Parse CPU info
    cpu = {}
    cpu_brand = re.search(r'\*\*Model:\*\*\s*(.+)', hw_section)
    cpu['brand'] = cpu_brand.group(1).strip() if cpu_brand else 'Unknown'

    cpu_arch = re.search(r'\*\*Architecture:\*\*\s*(.+)', hw_section)
    cpu['architecture'] = cpu_arch.group(1).strip() if cpu_arch else 'Unknown'

    cores_match = re.search(r'\*\*Cores:\*\*\s*(\d+)\s*physical,\s*(\d+)\s*logical', hw_section)
    if cores_match:
        cpu['cores_physical'] = int(cores_match.group(1))
        cpu['cores_logical'] = int(cores_match.group(2))
    else:
        cpu['cores_physical'] = 1
        cpu['cores_logical'] = 1

    freq_match = re.search(r'\*\*Frequency:\*\*\s*([\d.]+)', hw_section)
    cpu['frequency_mhz'] = float(freq_match.group(1)) if freq_match else 0

    # Parse Memory info
    memory = {}
    total_mem = re.search(r'### Memory.*?\*\*Total:\*\*\s*([\d.]+)\s*GB', hw_section, re.DOTALL)
    memory['total_gb'] = float(total_mem.group(1)) if total_mem else 0

    avail_mem = re.search(r'\*\*Available:\*\*\s*([\d.]+)\s*GB', hw_section)
    memory['available_gb'] = float(avail_mem.group(1)) if avail_mem else 0

    # Parse Disk info
    disk = {}
    total_disk = re.search(r'### Disk.*?\*\*Total:\*\*\s*([\d.]+)\s*GB', hw_section, re.DOTALL)
    disk['total_gb'] = float(total_disk.group(1)) if total_disk else 0

    free_disk = re.search(r'\*\*Free:\*\*\s*([\d.]+)\s*GB', hw_section)
    disk['free_gb'] = float(free_disk.group(1)) if free_disk else 0

    # Parse GPU info
    gpu = None
    gpu_section = re.search(r'### GPU\s*\n(.*?)(?=\n### |\Z)', hw_section, re.DOTALL)
    if gpu_section:
        gpu_text = gpu_section.group(1)
        if 'No GPU detected' not in gpu_text:
            gpu = {}
            gpu_model = re.search(r'\*\*Model:\*\*\s*(.+)', gpu_text)
            gpu['name'] = gpu_model.group(1).strip() if gpu_model else 'Unknown'

            gpu_mem = re.search(r'\*\*Memory:\*\*\s*([\d.]+)\s*GB', gpu_text)
            gpu['total_memory_gb'] = float(gpu_mem.group(1)) if gpu_mem else 0

            cuda_ver = re.search(r'\*\*CUDA Version:\*\*\s*(.+)', gpu_text)
            gpu['cuda_version'] = cuda_ver.group(1).strip() if cuda_ver else None

            compute = re.search(r'\*\*Compute Capability:\*\*\s*(.+)', gpu_text)
            gpu['compute_capability'] = compute.group(1).strip() if compute else None

            dev_count = re.search(r'\*\*Device Count:\*\*\s*(\d+)', gpu_text)
            gpu['device_count'] = int(dev_count.group(1)) if dev_count else 1

    return {
        'cpu': cpu,
        'memory': memory,
        'disk': disk,
        'gpu': gpu,
        'timestamp': None  # Not preserved in markdown
    }

def estimate_experiment_duration(config: dict, hardware_profile: dict) -> dict:
    """Estimate duration based on experiment config and hardware."""
    # Extract parameters from config.yaml
    num_samples = config.get('data', {}).get('num_samples', 10000)
    num_epochs = config.get('model', {}).get('epochs', 10)
    model_params = config.get('model', {}).get('estimated_params', 1000000)
    batch_size = config.get('model', {}).get('batch_size', 32)

    estimate = estimate_training_duration(
        num_samples=num_samples,
        num_epochs=num_epochs,
        model_params=model_params,
        hardware_profile=hardware_profile,
        batch_size=batch_size
    )

    return estimate

# Load hardware context
hardware_profile = parse_hardware_section(Path('.planning/DATA_REPORT.md'))

if hardware_profile:
    duration_estimate = estimate_experiment_duration(config, hardware_profile)

    print(f"\nDuration Estimate:")
    print(f"  Estimated time: {duration_estimate['estimated_minutes']:.1f} minutes")
    print(f"  Long-running: {duration_estimate['is_long_running']}")
    print(f"  Confidence: {duration_estimate['confidence']}")
else:
    # Fallback: assume potentially long-running without hardware context
    duration_estimate = {
        'is_long_running': True,
        'estimated_minutes': 60,
        'estimated_seconds': 3600,
        'confidence': 'LOW',
        'requires_user_confirmation': True
    }
    print("\nWARNING: No hardware profile in DATA_REPORT.md")
    print("  Duration estimate: Unknown (assuming potentially long-running)")
    print("  Recommendation: Run /grd:explore first for accurate estimates")
```

**Store duration_estimate in Internal State for Step 5 and README.md.**
```

2. Update Internal State section to track:
   - duration_estimate: DurationEstimate dict
   - long_running_approved: bool (session-level)
   - timeout_manager: ExperimentTimeoutManager instance
  </action>
  <verify>
Read agents/grd-researcher.md and confirm:
1. Step 1.6: Estimate Experiment Duration exists after Step 1.5
2. estimate_training_duration imported from src.grd.hardware
3. ExperimentTimeoutManager imported from src.grd.experiment
4. parse_hardware_section() function defined with full implementation
5. duration_estimate stored in Internal State
  </verify>
  <done>
Researcher agent estimates experiment duration at Step 1.6, loads hardware profile from DATA_REPORT.md via parse_hardware_section(), determines if long-running.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add timeout handling to experiment execution</name>
  <files>agents/grd-researcher.md</files>
  <action>
Update agents/grd-researcher.md Step 5 (Execute Experiment) to handle long-running experiments with session-level approval.

1. Add Step 5.0 before Step 5.1:

```markdown
## Step 5.0: Handle Long-Running Experiment Approval

**Responsibilities:**
- Check if experiment is long-running (from Step 1.6)
- Request session-level approval if needed (once per session)
- Configure timeout settings based on approval

### Session-Level Approval

```python
from src.grd.experiment import ExperimentTimeoutManager

# Initialize timeout manager (once per session)
if not hasattr(self, 'timeout_manager'):
    self.timeout_manager = ExperimentTimeoutManager()

if duration_estimate['is_long_running']:
    if not self.timeout_manager.long_running_approved:
        # Request approval (session-level)
        print(f"\n{'='*60}")
        print("LONG-RUNNING EXPERIMENT DETECTED")
        print(f"{'='*60}")
        print(f"Estimated duration: {duration_estimate['estimated_minutes']:.1f} minutes")
        print(f"This exceeds the standard 10-minute task timeout.")
        print(f"\nApproving long-running mode for this session.")
        print(f"No further prompts will appear during the experimentation loop.")
        print(f"{'='*60}\n")

        self.timeout_manager.request_long_running_approval(
            duration_estimate['estimated_minutes']
        )

    # Get appropriate timeout (None = no timeout)
    execution_timeout = self.timeout_manager.get_timeout(
        duration_estimate['estimated_seconds']
    )
else:
    execution_timeout = 600  # Standard 10-minute timeout

# Store for execution step
experiment_timeout = execution_timeout
```

**Session-level approval ensures:**
- User informed of expected duration ONCE
- No repeated prompts during REVISE_METHOD/REVISE_DATA loops
- Approval tracked in experiment metadata for audit
```

2. Update Step 5.1 (Direct Script Execution) to use experiment_timeout:

```python
# Execute with appropriate timeout
if experiment_timeout is not None:
    result = subprocess.run(
        ['python', 'code/train.py'],
        cwd=run_dir,
        capture_output=True,
        timeout=experiment_timeout
    )
else:
    # Long-running mode - no timeout
    result = subprocess.run(
        ['python', 'code/train.py'],
        cwd=run_dir,
        capture_output=True
    )
```

3. Update Step 5.1 for notebook experiments to pass timeout:

```python
# For notebook experiments
result = execute_notebook_experiment(
    notebook_path=input_notebook,
    run_dir=run_dir,
    parameters=parameters,
    execution_timeout=experiment_timeout or 3600  # Default 1 hour if no timeout
)
```
  </action>
  <verify>
Read agents/grd-researcher.md and confirm:
1. Step 5.0: Handle Long-Running Experiment Approval exists
2. ExperimentTimeoutManager initialized once per session
3. Session-level approval logic present
4. experiment_timeout variable used in execution
5. Both script and notebook execution paths handle timeout
  </verify>
  <done>
Researcher agent handles long-running experiments with session-level approval, configures timeout appropriately, no repeated prompts during iteration loop.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add checkpoint hints and hardware metadata</name>
  <files>agents/grd-researcher.md</files>
  <action>
Update agents/grd-researcher.md to include hardware context in metadata and provide checkpoint hints for resumability.

1. Update Step 2.2 (Generate README.md) to include hardware context:

Add to README.md template:
```markdown
## Hardware Context

{{hardware_summary}}

## Duration Estimate

- **Estimated:** {{estimated_minutes}} minutes
- **Long-running:** {{is_long_running}}
- **Confidence:** {{estimate_confidence}}
- **Timeout:** {{timeout_status}}
```

Populate with:
```python
hardware_summary = f"""
- CPU: {hardware_profile['cpu']['brand']} ({hardware_profile['cpu']['cores_physical']} cores)
- Memory: {hardware_profile['memory']['total_gb']:.1f} GB
- GPU: {hardware_profile['gpu']['name'] if hardware_profile['gpu'] else 'None'}
""" if hardware_profile else "Hardware profile not available"

update_readme_field("hardware_summary", hardware_summary)
update_readme_field("estimated_minutes", f"{duration_estimate['estimated_minutes']:.1f}")
update_readme_field("is_long_running", str(duration_estimate['is_long_running']))
update_readme_field("estimate_confidence", duration_estimate['confidence'])
update_readme_field("timeout_status", "Disabled (approved)" if experiment_timeout is None else f"{experiment_timeout}s")
```

2. Add Step 7.7.5 (Checkpoint Hints) after Step 7.7:

```markdown
## Step 7.7.5: Provide Checkpoint Hints (Long-Running Only)

**When:** Only for long-running experiments or when interrupted

**Responsibilities:**
- Check for saved checkpoints
- Provide resumability guidance
- Include hints in completion message

### Checkpoint Hints

```python
from src.grd.experiment import CheckpointHandler

if duration_estimate.get('is_long_running', False):
    # Initialize checkpoint handler for this run
    checkpoint_handler = CheckpointHandler(
        checkpoint_dir=Path(run_dir) / 'checkpoints'
    )

    hints = checkpoint_handler.get_resumability_hints()

    if hints['has_checkpoint']:
        print(f"\n{'='*60}")
        print("CHECKPOINT INFORMATION")
        print(f"{'='*60}")
        print(f"Latest checkpoint: Epoch {hints['latest_epoch']}")
        print(f"Checkpoint path: {hints['checkpoint_path']}")
        print(f"\nTo resume training:")
        print(f"  1. Load checkpoint in your training script")
        print(f"  2. Run: /grd:research --continue")
        print(f"{'='*60}\n")

    # Include in completion message
    checkpoint_info = {
        'has_checkpoint': hints['has_checkpoint'],
        'latest_epoch': hints.get('latest_epoch'),
        'checkpoint_path': str(hints.get('checkpoint_path'))
    }
```

3. Update Step 7.8 (Return Completion Message) to include checkpoint info:

```markdown
## RESEARCHER COMPLETE

**Run:** experiments/run_{NNN}_{description}/
**Iteration:** {iteration}
**Verdict:** {verdict} (Confidence: {confidence})

**Duration:**
- Estimated: {estimated_minutes} minutes
- Actual: {actual_minutes} minutes
- Timeout: {timeout_status}

**Checkpoint Status:** (for long-running only)
- Has checkpoint: {has_checkpoint}
- Latest epoch: {latest_epoch}
- Resume hint: {resume_hint}

**Artifacts:**
[... existing artifacts list ...]

**Routing:** {action_based_on_verdict}
```
  </action>
  <verify>
Read agents/grd-researcher.md and confirm:
1. README.md template includes Hardware Context and Duration Estimate sections
2. Step 7.7.5: Provide Checkpoint Hints exists
3. CheckpointHandler imported from src.grd.experiment
4. Completion message includes duration and checkpoint info
5. Resume hint provided for long-running experiments
  </verify>
  <done>
Researcher agent includes hardware context in experiment metadata, provides checkpoint hints for long-running experiments, completion message includes duration and resumability guidance.
  </done>
</task>

</tasks>

<verification>
1. Duration estimation integrated at Step 1.6
2. Timeout handling integrated at Step 5.0
3. Hardware context in README.md metadata
4. Checkpoint hints for long-running experiments
5. All imports from src.grd.hardware and src.grd.experiment present
</verification>

<success_criteria>
- [ ] Step 1.6: Estimate Experiment Duration added
- [ ] Step 5.0: Handle Long-Running Experiment Approval added
- [ ] Step 7.7.5: Provide Checkpoint Hints added
- [ ] Hardware context included in run README.md
- [ ] Duration estimate included in run README.md
- [ ] Session-level approval prevents repeated prompts
- [ ] Checkpoint hints provided for long-running experiments
- [ ] All modules imported from src.grd.hardware and src.grd.experiment
</success_criteria>

<output>
After completion, create `.planning/phases/09-hardware-profiling-long-running/09-04-SUMMARY.md`
</output>
