---
phase: 06-notebook-support
plan: 03
type: execute
wave: 2
depends_on: ["06-01"]
files_modified:
  - agents/grd-researcher.md
  - get-research-done/templates/experiment-readme.md
autonomous: true

must_haves:
  truths:
    - "Researcher agent detects notebook vs script inputs"
    - "Researcher agent executes notebooks via notebook_executor"
    - "Notebook runs save executed notebook + extracted metrics"
    - "Experiment README distinguishes notebook vs script runs"
  artifacts:
    - path: "agents/grd-researcher.md"
      provides: "Updated agent with notebook execution support"
      contains: "notebook_executor"
      contains: ".ipynb"
    - path: "get-research-done/templates/experiment-readme.md"
      provides: "Updated template for notebook run metadata"
      contains: "notebook"
  key_links:
    - from: "agents/grd-researcher.md"
      to: "src/grd/notebook_executor.py"
      via: "Import and call execute_notebook_experiment"
      pattern: "execute_notebook_experiment"
    - from: "agents/grd-researcher.md"
      to: "experiments/run_NNN/output.ipynb"
      via: "Notebook execution output path"
      pattern: "output\\.ipynb"
---

<objective>
Update grd-researcher agent to support notebook execution alongside script execution.

Purpose: Enable notebooks in `notebooks/exploration/` to run through the GRD validation loop (Researcher -> Critic -> Evaluator) with the same rigor as Python scripts, producing structured outputs and supporting Critic evaluation.

Output:
- Updated `agents/grd-researcher.md` with notebook detection and execution
- Updated `get-research-done/templates/experiment-readme.md` for notebook runs
</objective>

<execution_context>
@/Users/evanowen/.claude/get-research-done/workflows/execute-plan.md
@/Users/evanowen/.claude/get-research-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-notebook-support/06-CONTEXT.md
@.planning/phases/06-notebook-support/06-RESEARCH.md
@.planning/phases/06-notebook-support/06-01-SUMMARY.md
@agents/grd-researcher.md
@get-research-done/templates/experiment-readme.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update grd-researcher agent for notebook support</name>
  <files>agents/grd-researcher.md</files>
  <action>
Read and update `agents/grd-researcher.md` to add notebook execution support.

**Add to role section:**
Add under "You create:" list:
- For notebooks: Executed notebook (output.ipynb) in run directory

**Add Step 1.5: Detect Experiment Type**

Insert after Step 1.4 (Determine Run Number and Description):

```markdown
### 1.5 Detect Experiment Type

Determine if implementing as notebook or script based on:

1. **Explicit argument:** If task prompt includes `--notebook` flag, use notebook
2. **File extension:** If existing experiment path ends in `.ipynb`, use notebook
3. **Default:** Python script (train.py)

**For notebook experiments:**
- Source notebook must exist in `notebooks/exploration/`
- Will execute via papermill with parameters injected
- Will save executed notebook as `output.ipynb` + metrics.json
- MUST validate random_seed in parameters (hard requirement)

**Store experiment type for later steps:**
```python
experiment_type = 'notebook' | 'script'
source_path = 'notebooks/exploration/001_experiment.ipynb' | None
```
```

**Update Step 4: Generate Code**

Add notebook handling branch:

```markdown
### 4.1 For Notebook Experiments

If experiment_type == 'notebook':

1. **Copy source notebook to run directory:**
   ```bash
   cp notebooks/exploration/{source}.ipynb experiments/run_{NNN}_{desc}/code/input.ipynb
   ```

2. **Verify parameters cell exists:**
   Check notebook has cell tagged 'parameters' for papermill injection.
   If not, warn: "Notebook missing 'parameters' cell tag - parameters will be added as new cell"

3. **Prepare parameters dict:**
   Must include at minimum:
   - random_seed: 42 (from OBJECTIVE.md evaluation.random_state or default)
   - data_path: path to data (from DATA_REPORT.md or config)
   - Any hyperparameters from config.yaml

4. **Do NOT modify notebook source** - papermill will inject parameters at execution

### 4.2 For Script Experiments

(Keep existing Step 4 logic for script generation)
```

**Update Step 5: Execute Experiment**

Add notebook execution branch:

```markdown
### 5.1 For Notebook Experiments

If experiment_type == 'notebook':

Use the notebook executor module:

```python
from src.grd.notebook_executor import execute_notebook_experiment
from pathlib import Path

result = execute_notebook_experiment(
    notebook_path='experiments/run_{NNN}_{desc}/code/input.ipynb',
    run_dir=Path('experiments/run_{NNN}_{desc}'),
    parameters={
        'random_seed': 42,
        'data_path': '{data_path}',
        # ... other parameters from config.yaml
    },
    execution_timeout=300,  # 5 min per cell
    retry_on_failure=True
)

if not result['success']:
    # Log failure, save partial notebook if exists
    # Update README.md status to 'failed'
    # Exit with failure state for Critic
else:
    # Metrics saved to experiments/run_{NNN}_{desc}/metrics.json
    # Executed notebook at experiments/run_{NNN}_{desc}/output.ipynb
```

**Key differences from script execution:**
- Notebook saves BOTH input.ipynb (original) AND output.ipynb (executed with outputs)
- Metrics extracted via scrapbook, not parsed from stdout
- Cell-level timeout prevents infinite loops
- Fresh kernel ensures reproducibility

### 5.2 For Script Experiments

(Keep existing Step 5 logic for script execution)
```

**Update Step 6: Collect Metrics**

Add notebook metrics handling:

```markdown
### 6.1 For Notebook Experiments

If experiment_type == 'notebook':

Metrics already extracted by notebook_executor to `metrics.json`.

Load and format for SCORECARD:
```python
import json
from pathlib import Path

metrics_path = Path('experiments/run_{NNN}_{desc}/metrics.json')
with open(metrics_path) as f:
    raw_metrics = json.load(f)

# Map to OBJECTIVE.md success criteria format
# ...
```

### 6.2 For Script Experiments

(Keep existing Step 6 logic)
```

**Update config.yaml structure section:**

Add notebook-specific fields:

```yaml
# For notebook experiments
experiment_type: notebook
source_notebook: notebooks/exploration/001_experiment.ipynb

# Parameters to inject via papermill
parameters:
  random_seed: 42
  data_path: data/train.csv
  # ... other hyperparameters
```
  </action>
  <verify>
Check notebook detection logic exists: `grep -c "experiment_type" agents/grd-researcher.md`
Check notebook executor reference: `grep "notebook_executor" agents/grd-researcher.md`
Check .ipynb handling: `grep -c "\\.ipynb" agents/grd-researcher.md`
  </verify>
  <done>
- grd-researcher.md has Step 1.5 for experiment type detection
- Step 4 branches for notebook vs script code generation
- Step 5 branches for notebook execution via notebook_executor
- Step 6 handles notebook metrics from metrics.json
- config.yaml structure includes notebook-specific fields
  </done>
</task>

<task type="auto">
  <name>Task 2: Update experiment README template for notebooks</name>
  <files>get-research-done/templates/experiment-readme.md</files>
  <action>
Read and update `get-research-done/templates/experiment-readme.md` to support notebook runs.

**Add experiment type field:**

In the metadata section, add:
```markdown
- **Experiment Type:** {{experiment_type}} (script | notebook)
```

**Add notebook-specific section:**

Add conditional section after Overview:

```markdown
{{#if experiment_type == 'notebook'}}
## Notebook Execution

- **Source Notebook:** {{source_notebook}}
- **Input Notebook:** code/input.ipynb (copy of source)
- **Executed Notebook:** output.ipynb (with outputs)
- **Metrics Extracted:** metrics.json (via scrapbook)

### Parameters Injected

The following parameters were injected via papermill:

| Parameter | Value |
|-----------|-------|
{{#each parameters}}
| {{key}} | {{value}} |
{{/each}}

### Execution Details

- **Kernel:** {{kernel_name}} (auto-detected)
- **Cell Timeout:** {{cell_timeout}} seconds
- **Execution Time:** {{execution_time_seconds}} seconds
- **Retry Attempted:** {{retry_attempted}} (true/false)

{{/if}}
```

**Update Files section:**

Add notebook-specific files:

```markdown
## Files

{{#if experiment_type == 'notebook'}}
- `code/input.ipynb` - Original notebook (source copy)
- `output.ipynb` - Executed notebook with outputs
- `metrics.json` - Extracted metrics (via scrapbook)
{{else}}
- `code/train.py` - Training script
{{/if}}
- `config.yaml` - Experiment configuration
- `data/` - Data references (symlinks + hashes)
- `logs/` - Execution logs
- `outputs/` - Model artifacts
- `metrics/SCORECARD.json` - Evaluation results
- `CRITIC_LOG.md` - Critic verdict
```

**Note:** Use simple conditional markers that the agent can interpret. Not actual templating syntax - agent will fill in appropriate sections based on experiment type.
  </action>
  <verify>
Check template has notebook section: `grep -c "notebook" get-research-done/templates/experiment-readme.md`
Check template has experiment type: `grep "Experiment Type" get-research-done/templates/experiment-readme.md`
  </verify>
  <done>
- Experiment README template includes experiment_type field
- Template has notebook-specific section for source, input, output notebooks
- Template includes parameters table for papermill injection
- Template includes execution details (kernel, timeout, retry)
- Template files section distinguishes notebook vs script runs
  </done>
</task>

</tasks>

<verification>
1. grd-researcher.md handles notebook experiments: `grep -A5 "experiment_type" agents/grd-researcher.md`
2. grd-researcher.md references notebook_executor: `grep "execute_notebook_experiment" agents/grd-researcher.md`
3. experiment-readme.md has notebook fields: `grep "Notebook Execution" get-research-done/templates/experiment-readme.md`
</verification>

<success_criteria>
- grd-researcher agent detects notebook vs script experiments
- Agent executes notebooks via notebook_executor module
- Agent saves both input.ipynb and output.ipynb for notebooks
- Experiment README template distinguishes notebook runs
- README includes parameterization and execution details for notebooks
</success_criteria>

<output>
After completion, create `.planning/phases/06-notebook-support/06-03-SUMMARY.md`
</output>
