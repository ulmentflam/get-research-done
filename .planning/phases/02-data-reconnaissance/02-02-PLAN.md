---
phase: 02-data-reconnaissance
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - agents/grd-explorer.md
autonomous: true

must_haves:
  truths:
    - "Explorer agent can load CSV, Parquet, and compressed files"
    - "Explorer agent can stream from S3 and GCS using smart_open"
    - "Explorer agent performs reservoir sampling for large datasets"
    - "Explorer agent profiles numerical and categorical distributions"
    - "Explorer agent detects outliers using Z-score and IQR methods"
    - "Explorer agent analyzes missing data patterns"
  artifacts:
    - path: "agents/grd-explorer.md"
      provides: "Complete data loading and profiling logic"
      contains: "smart_open"
    - path: "agents/grd-explorer.md"
      provides: "Outlier detection instructions"
      contains: "Z-score"
    - path: "agents/grd-explorer.md"
      provides: "Missing data analysis"
      contains: "MCAR"
  key_links:
    - from: "agents/grd-explorer.md"
      to: "pandas/pyarrow"
      via: "Python code patterns"
      pattern: "pd\\.read_csv|pq\\.read_table"
    - from: "agents/grd-explorer.md"
      to: "scipy.stats"
      via: "Statistical analysis"
      pattern: "zscore|chi2_contingency"
---

<objective>
Implement Explorer agent data loading, sampling, and statistical profiling logic

Purpose: This plan completes the data loading and profiling portions of the Explorer agent. After this plan, the agent can load data from local files and cloud storage, apply sampling for large datasets, and generate comprehensive distribution statistics.

Output: Fully functional data loading and profiling sections in grd-explorer.md
</objective>

<execution_context>
@/Users/evanowen/.claude/get-research-done/workflows/execute-plan.md
@/Users/evanowen/.claude/get-research-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-data-reconnaissance/02-CONTEXT.md
@.planning/phases/02-data-reconnaissance/02-RESEARCH.md
@.planning/phases/02-data-reconnaissance/02-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement data loading logic in Explorer agent</name>
  <files>agents/grd-explorer.md</files>
  <action>
Replace the placeholder load_data step in grd-explorer.md with complete data loading logic.

Based on CONTEXT.md decisions and RESEARCH.md patterns, implement:

1. **Input handling:**
   - If path provided: validate it exists (local) or is accessible (cloud)
   - If no path: interactively detect data files in current directory and let user select
   - Auto-detect train/test/val splits (if train.csv exists, look for test.csv, val.csv)

2. **Format detection and loading:**
   ```python
   # Local files
   if path.endswith('.csv') or path.endswith('.csv.gz'):
       df = pd.read_csv(path)
   elif path.endswith('.parquet') or path.endswith('.parquet.gz'):
       df = pd.read_parquet(path)

   # Cloud files (s3://, gs://)
   if path.startswith('s3://') or path.startswith('gs://'):
       import smart_open
       with smart_open.open(path, 'rb') as f:
           # Stream and process
   ```

3. **Column type inference:**
   - Auto-infer numeric, categorical, datetime, text columns
   - Prompt user to confirm target column (or "No target" for unsupervised)
   - Identify likely ID columns (high cardinality, naming patterns like *_id, id_*)

4. **Compression handling:**
   - Auto-decompress .gz, .zip files transparently
   - Note decompression in report

5. **Error handling:**
   - File not found: Clear error message with path checked
   - Auth error for cloud: Prompt for credentials setup
   - Encoding issues: Try utf-8, then latin-1, then report

Include the Python code patterns from RESEARCH.md Pattern 2 (Parquet with PyArrow) and Pattern 3 (Memory-Efficient Data Types).
  </action>
  <verify>
    - `grep "smart_open" agents/grd-explorer.md` returns a match
    - `grep "pd.read_csv" agents/grd-explorer.md` returns a match
    - `grep "pd.read_parquet\|pq.read_table" agents/grd-explorer.md` returns a match
    - Agent file contains instructions for handling s3:// and gs:// paths
  </verify>
  <done>
    Explorer agent has complete data loading logic for local and cloud files
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement sampling and profiling logic</name>
  <files>agents/grd-explorer.md</files>
  <action>
Add sampling and statistical profiling logic to grd-explorer.md.

1. **Sampling for large datasets:**
   - If rows > 100,000: Apply reservoir sampling (Algorithm R from RESEARCH.md)
   - Document sampling in report: "Sampled 100,000 rows from {total} rows using reservoir sampling"
   - Use seed=42 for reproducibility

   ```python
   SAMPLE_SIZE = 100000
   if len(df) > SAMPLE_SIZE:
       df_sample = df.sample(n=SAMPLE_SIZE, random_state=42)
       sampling_note = f"Sampled {SAMPLE_SIZE:,} rows from {len(df):,} total"
   else:
       df_sample = df
       sampling_note = "Full dataset analyzed (no sampling needed)"
   ```

2. **Numerical column profiling:**
   - Compute: mean, std, min, 25%, 50%, 75%, max
   - Compute: skewness, kurtosis (if --detailed flag)
   - Use: `df.describe()` and `scipy.stats.skew/kurtosis`

3. **Categorical column profiling:**
   - Compute: unique count, top value, top frequency
   - Use: `df[col].value_counts()`

4. **Class balance detection (if target specified):**
   - Compute class distribution
   - Calculate imbalance ratio (minority/majority)
   - Classify severity: LOW (>0.5), MEDIUM (0.1-0.5), HIGH (<0.1)
   - Include recommendation based on severity

5. **Missing data analysis:**
   - Count and percentage per column
   - Pattern analysis using chi-square test (from RESEARCH.md Pattern 7)
   - Classify as MCAR/MAR/MNAR with confidence level
   - List related variables for MAR patterns

6. **Outlier detection:**
   - Z-score method: |z| > 3 threshold
   - IQR method: < Q1-1.5*IQR or > Q3+1.5*IQR
   - Report both methods, note severity
   - List top N specific anomalous values with explanations

Include the code patterns from RESEARCH.md Pattern 4 (Statistical Outlier Detection) and Pattern 7 (Missing Data Pattern Analysis).

Add a note about pandas 3.0 breaking changes from RESEARCH.md Pitfall 1 (use .loc instead of chained assignment).
  </action>
  <verify>
    - `grep "reservoir\|SAMPLE_SIZE\|random_state=42" agents/grd-explorer.md` returns matches
    - `grep "zscore\|Z-score" agents/grd-explorer.md` returns a match
    - `grep "IQR" agents/grd-explorer.md` returns a match
    - `grep "MCAR\|MAR\|MNAR" agents/grd-explorer.md` returns matches
    - `grep "imbalance_ratio\|class.*balance" agents/grd-explorer.md` returns a match
  </verify>
  <done>
    Explorer agent has complete sampling and profiling logic for all data types
  </done>
</task>

</tasks>

<verification>
Run comprehensive verification:

```bash
echo "=== Verifying Explorer Agent Data Loading & Profiling ==="

echo "1. Data loading patterns present:"
grep -c "pd.read_csv\|pd.read_parquet\|smart_open\|pq.read_table" agents/grd-explorer.md

echo "2. Cloud storage support:"
grep -E "s3://|gs://" agents/grd-explorer.md | head -3

echo "3. Sampling logic:"
grep -E "reservoir|SAMPLE_SIZE|100.?000|random_state" agents/grd-explorer.md | head -3

echo "4. Outlier detection methods:"
grep -E "zscore|Z-score|IQR" agents/grd-explorer.md | head -3

echo "5. Missing data analysis:"
grep -E "MCAR|MAR|MNAR|chi2_contingency" agents/grd-explorer.md | head -3

echo "6. Class balance detection:"
grep -E "imbalance|class.*balance|minority.*majority" agents/grd-explorer.md | head -3

echo "7. Pandas 3.0 awareness:"
grep -E "\.loc\[|CoW|copy-on-write" agents/grd-explorer.md | head -2
```
</verification>

<success_criteria>
- Explorer agent can load CSV, Parquet, and compressed files
- Explorer agent handles s3:// and gs:// paths via smart_open
- Reservoir sampling implemented for datasets > 100k rows
- Numerical and categorical profiling complete
- Outlier detection with Z-score and IQR methods
- Missing data pattern analysis with MCAR/MAR/MNAR classification
- Class balance detection with severity and recommendations
- All code patterns follow pandas 3.0 best practices
</success_criteria>

<output>
After completion, create `.planning/phases/02-data-reconnaissance/02-02-SUMMARY.md`
</output>
